{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to find out what exactly a neural network learns is to look at the function of each neuron individually. Although there's no easy way to disentangle a single neuron from the rest of the network, we can try to figure out what kind of input is recognized by that neuron - and that gives us some insight into its role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we train a neural network on the digits dataset from scikit-learn, which contains 1797 8x8 images of handwritten digits. We then initialize the input with a random image, and instead of using gradient descent to optimize the weights to minimize the loss, we use it to optimize the input image to maximize the activation of a particular neuron. Visualizing this optimized image can then tell us something about what that neuron responds to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "X_scaled = (digits.data - np.min(digits.data))/(np.max(digits.data) - np.min(digits.data))\n",
    "\n",
    "# Convert X and y into PyTorch tensors and apply a one-hot encoding to y\n",
    "X = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y = torch.nn.functional.one_hot(torch.tensor(digits.target, dtype=torch.long)).float()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(n_inputs, n_hidden)\n",
    "        self.layer2 = torch.nn.Linear(n_hidden, n_outputs)\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "    \n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, n_hidden, n_outputs):\n",
    "        super().__init__()\n",
    "        self.conv2d = torch.nn.Conv2d(1, n_hidden, kernel_size=(8,1))\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc = torch.nn.Linear(128, n_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "model = NeuralNetwork(64, 16, 10)\n",
    "\n",
    "model_cnn = ConvNet(16, 10)\n",
    "\n",
    "loss_criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_cnn.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(X_train)):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model_cnn(torch.reshape(X_train[i], (8,8)).unsqueeze(0).unsqueeze(0)) \n",
    "        loss = loss_criterion(y_pred[0], y_train[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained the network, we take each of the 10 output neurons in turn and try to maximize its activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off weight updating during backprop\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_iterations = 2500\n",
    "\n",
    "images = []\n",
    "\n",
    "for k in range(10):\n",
    "    input_tensor = torch.randn(1, 1, 8, 8, requires_grad=True)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        output = model_cnn(input_tensor)\n",
    "        output[0][k].backward()\n",
    "        input_tensor.data += learning_rate * input_tensor.grad.data\n",
    "        input_tensor.grad.zero_()\n",
    "        \n",
    "    img = input_tensor.detach().numpy().reshape((8, 8))\n",
    "    img = (img - np.min(img))/(np.max(img) - np.min(img))*256\n",
    "\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 1))\n",
    "\n",
    "for i in range(len(images)):\n",
    "    fig.add_subplot(1, 10, i+1)\n",
    "    plt.imshow(images[i], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.title(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above images, it's clear that each output neuron responds most strongly to an image that looks at least vaguely like the digit that it predicts. We can see this for 0, 2, 3 and 5, and make out shapes in the other images that correspond to parts of the associated digits (for example, the optimized image for 8 looks like an X - that's what that neuron detects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
